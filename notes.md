robots.txt adalah file teks sederhana yang ditempatkan di direktori root situs web Anda dan digunakan untuk mengontrol bagaimana mesin pencari (seperti Google, Bing, dll.) merayapi (crawl) dan mengindeks halaman di situs Anda. Dengan kata lain, file ini memberikan instruksi kepada web crawlers atau "bots" tentang bagian mana dari situs yang mereka diizinkan atau tidak diizinkan untuk diakses.